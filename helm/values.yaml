# Global settings
global:
  domain: api.meatheadmathematician.com
  environment: test

# Milvus configuration
milvus:
  enabled: true
  mode: standalone
  storageClass: ""
  image:
    all:
      repository: milvusdb/milvus
      # tag: "v2.4.15"
      pullPolicy: Always
  persistence:
    persistentVolumeClaim:
      enabled: true
      storageClass: ""
      size: 16Gi
  standalone:
    resources:
      requests:
        cpu: 500m
        memory: 2Gi
      limits:
        cpu: 1000m
        memory: 4Gi
  minio:
    enabled: true
    mode: standalone
    persistence:
      enabled: true
      storageClass: ""
      size: 16Gi
    resources:
      limits:
        cpu: 500m
        memory: 1Gi
      requests:
        cpu: 250m
        memory: 512Mi
  etcd:
    enabled: true
    # size
    replicaCount: 1
  cluster:
    enabled: false
  pulsar:
    enabled: false
  pulsarv3:
    enabled: false

# OpenWebUI configuration
open-webui:
  enabled: true
  image:
    repository: ghcr.io/open-webui/open-webui
    # tag: "main"
    pullPolicy: Always
  replicaCount: 1
  service:
    type: ClusterIP
    port: 8080
    targetPort: 8080
  persistence:
    enabled: true
    size: 4Gi
    storageClass: ""
  resources:
    limits:
      cpu: 500m
      memory: 2Gi
    requests:
      cpu: 500m
      memory: 1Gi
  ingress:
    enabled: true
    class: "nginx"
    annotations:
      nginx.ingress.kubernetes.io/ssl-redirect: "false"
    host: "oi.{{ .Values.global.domain }}"
  ollama:
    enabled: false
  ollamaUrls:
    - "http://ollama.{{ .Values.global.environment }}.svc.cluster.local:11434"

# Ollama configuration - we'll create this as a custom deployment
ollama:
  enabled: true
  image:
    repository: ollama/ollama
    # tag: "latest"
    pullPolicy: Always
  # service:
  #   type: ClusterIP
  #   port: 11434
  #   targetPort: 11434
  # persistence:
  #   enabled: true
  #   size: 24Gi
  #   storageClass: ""
  resources:
    requests:
      cpu: 1000m
      memory: 4Gi
    limits:
      cpu: 2000m
      memory: 8Gi
  ollama:
    gpu:
      enabled: false
    models:
      pull:
        - qwen3:1.7b
        - phi4-reasoning:14b
        - granite3.2-vision:2b
  ingress:
    enabled: false
